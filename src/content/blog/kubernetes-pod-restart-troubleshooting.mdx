---
title: "Kubernetes Pod가 계속 재시작되는 문제 해결기"
date: 2024-12-01
summary: "CrashLoopBackOff 상태의 Pod를 디버깅하고 해결한 과정을 공유합니다."
tags: ["Kubernetes", "Troubleshooting", "DevOps", "Container"]
category: "troubleshooting"
---

## 현상

운영 환경에서 특정 서비스의 Pod가 CrashLoopBackOff 상태로 계속 재시작되는 현상이 발생했습니다.

```bash
$ kubectl get pods -n production
NAME                        READY   STATUS             RESTARTS   AGE
api-server-7d4f8b9-x2k9l    0/1     CrashLoopBackOff   15         23m
api-server-7d4f8b9-m3n8p    0/1     CrashLoopBackOff   15         23m
```

## 진단 과정

### Step 1: Pod 상태 확인

```bash
$ kubectl describe pod api-server-7d4f8b9-x2k9l -n production
```

```yaml
State:          Waiting
  Reason:       CrashLoopBackOff
Last State:     Terminated
  Reason:       OOMKilled
  Exit Code:    137
```

**단서**: `OOMKilled` - 메모리 부족으로 강제 종료

### Step 2: 리소스 설정 확인

```bash
$ kubectl get pod api-server-7d4f8b9-x2k9l -n production -o yaml | grep -A 10 resources
```

```yaml
resources:
  limits:
    memory: "256Mi"
  requests:
    memory: "128Mi"
```

설정된 메모리 limit이 256Mi로, 실제 필요량 대비 너무 낮았습니다.

### Step 3: 애플리케이션 로그 확인

```bash
$ kubectl logs api-server-7d4f8b9-x2k9l -n production --previous
```

```
java.lang.OutOfMemoryError: Java heap space
    at java.util.Arrays.copyOf(Arrays.java:3236)
    at java.util.ArrayList.grow(ArrayList.java:265)
    ...
```

**확인**: JVM 힙 메모리 부족

### Step 4: 메모리 사용량 모니터링

```bash
$ kubectl top pod api-server-7d4f8b9-x2k9l -n production
NAME                        CPU(cores)   MEMORY(bytes)
api-server-7d4f8b9-x2k9l    45m          243Mi
```

limit(256Mi)에 근접한 메모리 사용량 확인

## 원인 분석

### 근본 원인

1. **JVM 기본 설정 문제**: 컨테이너 메모리 limit을 인식하지 못하고 호스트 메모리 기준으로 힙 크기 계산
2. **최근 트래픽 증가**: 신규 기능 출시 후 요청량 2배 증가
3. **캐시 데이터 증가**: 인메모리 캐시 사이즈 제한 없음

### 왜 갑자기 발생했나?

- 기존에는 충분한 여유가 있었으나
- 트래픽 증가 + 캐시 데이터 축적으로 임계점 도달

## 해결 방안

### 1단계: 긴급 조치 (메모리 limit 증가)

```yaml
# deployment.yaml
resources:
  limits:
    memory: "512Mi"
  requests:
    memory: "256Mi"
```

```bash
$ kubectl apply -f deployment.yaml
$ kubectl rollout status deployment/api-server -n production
```

### 2단계: JVM 옵션 최적화

```yaml
# deployment.yaml
env:
  - name: JAVA_OPTS
    value: >-
      -XX:+UseContainerSupport
      -XX:MaxRAMPercentage=75.0
      -XX:InitialRAMPercentage=50.0
      -XX:+HeapDumpOnOutOfMemoryError
      -XX:HeapDumpPath=/tmp/heapdump.hprof
```

**주요 옵션 설명:**
- `UseContainerSupport`: 컨테이너 메모리 limit 인식 (Java 8u191+)
- `MaxRAMPercentage=75.0`: 컨테이너 메모리의 75%를 힙으로 사용
- `HeapDumpOnOutOfMemoryError`: OOM 발생 시 힙 덤프 생성

### 3단계: 캐시 사이즈 제한

```java
@Configuration
public class CacheConfig {
    @Bean
    public CacheManager cacheManager() {
        CaffeineCacheManager manager = new CaffeineCacheManager();
        manager.setCaffeine(Caffeine.newBuilder()
            .maximumSize(10_000)        // 최대 엔트리 수 제한
            .expireAfterWrite(1, TimeUnit.HOURS)
            .recordStats());
        return manager;
    }
}
```

### 4단계: 모니터링 및 알림 설정

```yaml
# Prometheus AlertManager rule
groups:
  - name: memory-alerts
    rules:
      - alert: PodMemoryHigh
        expr: |
          (container_memory_usage_bytes / container_spec_memory_limit_bytes) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Pod {{ $labels.pod }} 메모리 사용률 80% 초과"
```

## 결과 확인

### 적용 후 상태

```bash
$ kubectl get pods -n production
NAME                        READY   STATUS    RESTARTS   AGE
api-server-8e5f9c0-a1b2c    1/1     Running   0          45m
api-server-8e5f9c0-d3e4f    1/1     Running   0          45m
```

### 메모리 사용량 변화

| 시점 | 메모리 사용량 | Limit | 사용률 |
|------|-------------|-------|--------|
| 수정 전 | 243Mi | 256Mi | 95% |
| 수정 후 | 320Mi | 512Mi | 62% |

## 재발 방지 대책

### 1. Resource Quota 가이드라인

```yaml
# 서비스별 권장 리소스 설정
api-service:
  small:   { memory: 512Mi, cpu: 250m }
  medium:  { memory: 1Gi, cpu: 500m }
  large:   { memory: 2Gi, cpu: 1000m }
```

### 2. Vertical Pod Autoscaler 도입 검토

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: api-server-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-server
  updatePolicy:
    updateMode: "Auto"
```

### 3. 부하 테스트 프로세스

- 새 버전 배포 전 부하 테스트 필수화
- 메모리 사용량 프로파일링 포함

## 교훈

1. **컨테이너 환경에서 JVM 튜닝 필수**: 기본 설정으로는 문제 발생 가능
2. **메모리 여유분 확보**: limit의 80% 이상 사용 시 경고 설정
3. **점진적 모니터링 중요**: 갑작스러운 장애는 대부분 축적된 문제의 결과

## 참고 자료

- [Kubernetes: Managing Resources for Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)
- [Java Memory Settings in a Container Environment](https://developers.redhat.com/articles/2022/04/19/java-17-whats-new-openjdks-container-awareness)
